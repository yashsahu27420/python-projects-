{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPUWjnPIUFjfQRaxB1+Mm1R"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EE3ekqMFLbdQ"
      },
      "outputs": [],
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import requests.exceptions\n",
        "import urllib.parse\n",
        "from collections import deque\n",
        "import re\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Email web scraping\n",
        "\"\"\" Implemented effective email web scraping techniques, extracting and analyzing data for valuable insights. Demonstrated expertise in data extraction, cleaning, and analysis for actionable results.\"\"\"\n",
        "#https://www.speakrj.com/audit/top/youtube\n",
        "user_url = str(input('[+] Enter target URL to scan: '))\n",
        "uls = deque([user_url])\n",
        "\n",
        "scraped_urls = set()\n",
        "gmails = set()\n",
        "\n",
        "count = 0\n",
        "try:\n",
        "  while len(uls):\n",
        "    count += 1\n",
        "    if count == 10:\n",
        "      break\n",
        "    url = uls.popleft()\n",
        "    scraped_urls.add(url)\n",
        "\n",
        "    parts = urllib.parse.urlsplit(url)\n",
        "    base_url = '{0.scheme}://{0.netloc}'.format(parts)\n",
        "\n",
        "    path = url[:url.rfind('/')+1] if '/' in parts.path else url\n",
        "\n",
        "    print('[%d] Processing %s' % (count, url))\n",
        "    try:\n",
        "      response = requests.get(url)\n",
        "    except (requests.exceptions.MissingSchema, requests.exceptions.ConnectionError):\n",
        "      continue\n",
        "\n",
        "    new_emails = set(re.findall(r'[a-z0-9\\.\\-+_]+@[a-z0-9\\.\\-+_]+\\.[a-z]+', response.text, re.I))\n",
        "    gmails.update(new_emails)\n",
        "\n",
        "    soup = BeautifulSoup(response.text, features=\"lxml\")\n",
        "\n",
        "    for anc in soup.find_all(\"a\"):\n",
        "      link = anc.attrs['href'] if 'href' in anc.attrs else ''\n",
        "      if link.startswith('/'):\n",
        "        link = base_url + link\n",
        "      elif not link.startswith('http'):\n",
        "        link = path + link\n",
        "      if not link in uls and not link in scraped_urls:\n",
        "        uls.append(link)\n",
        "except KeyboardInterrupt:\n",
        "  print('[-] Closing!')\n",
        "\n",
        "for mail in gmails:\n",
        "  print(mail)\n"
      ],
      "metadata": {
        "id": "y49w-TzM58hv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f96cd054-64b9-4e5f-851f-e333adda3b5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[+] Enter target URL to scan: https://www.speakrj.com/audit/top/youtube\n",
            "[1] Processing https://www.speakrj.com/audit/top/youtube\n",
            "[2] Processing https://www.speakrj.com/audit/\n",
            "[3] Processing https://www.speakrj.com/audit/top/#\n",
            "[4] Processing https://www.speakrj.com/audit/top/platform/instagram\n",
            "[5] Processing https://www.speakrj.com/audit/top/platform/twitter\n",
            "[6] Processing https://www.speakrj.com/audit/top/platform/youtube\n",
            "[7] Processing https://www.speakrj.com/audit/top/platform/facebook\n",
            "[8] Processing https://www.speakrj.com/audit/top/compare/instagram\n",
            "[9] Processing https://www.speakrj.com/audit/top/compare/twitter\n",
            "ryantrahan@night.co\n",
            "contacto@yeseniaThen.com\n",
            "sirgibsy@goldeninfluence.com\n",
            "navyhato@gmail.com\n",
            "itsbaba36@gmail.com\n",
            "contact@beterbocukteam.com\n",
            "bababusinessofficial5@gmail.com\n",
            "music@muze.bg\n",
            "kunaltomar934@gmail.com\n",
            "xdjames.anm@gmail.com\n",
            "businessneonman@gmail.com\n",
            "connect@monamighosh.com\n",
            "marcaskim@gmail.com\n",
            "DigitalBethanyMotaTeam@unitedtalent.com\n",
            "luisitocomunica@wearedw.com\n",
            "business@aburob.com\n",
            "kaka@nonstopproducoes.com.br\n",
            "contactcwitchy@gmail.com\n",
            "officialbanwarilal@gmail.com\n",
            "artbyaryan@gmail.com\n",
            "TheExposeUnit@gmail.com\n",
            "TheHollywoodFix@gmail.co\n",
            "avinashpatel91185261@gmail.com\n",
            "AirwaveRecords@gmail.com\n",
            "jankylanky@moreyellow.com\n",
            "Beaniemillietv@gmail.com\n",
            "contato@ojeanluca.com\n",
            "lusquinhafarias@gmail.com\n",
            "dhirumonchik@gmail.com\n",
            "pxrgebusiness@gmail.com\n",
            "business@krinios.com\n",
            "shfaworld@gmail.com\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#News extraction using web scraping\n",
        "\"Efficiently utilized web scraping techniques in Python to extract and analyze news data, demonstrating expertise in data retrieval and content aggregation for insightful decision-making.\"\n",
        "url = \"https://www.businesstoday.in/latest/corporate\"\n",
        "req = requests.get(url)\n",
        "soup = BeautifulSoup(req.content, 'html.parser')\n",
        "\n",
        "rawdata = soup.find_all(\"div\", class_=\"section-listing-LHS\", limit=6)\n",
        "\n",
        "news_titles = []\n",
        "for data in rawdata:\n",
        "    news = data.div.div.h2.a[\"title\"]\n",
        "    news_titles.append(str(news))\n",
        "\n",
        "print(news_titles)\n"
      ],
      "metadata": {
        "id": "hN1Rm3wlBf9Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86f7251c-26aa-4140-f05d-f43f8bc0c911"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Infosys kicks off long-awaited pay hike for employees ahead of holiday season: Report']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LuMeSgHBBgAN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}